{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from RNN import SentimentRNN\n",
    "import torchtext.data as data\n",
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "# gensim\n",
    "import gensim.downloader\n",
    "\n",
    "# word processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# utils\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from collections import Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "glove_embeddings = gensim.downloader.load('glove-twitter-25')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/IMDB-Dataset.csv')  # could also download this from torchtext.datasets\n",
    "# make everything lower case\n",
    "cleaned_df = df.sample(frac=0.25)\n",
    "cleaned_df = df.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "# https://stackoverflow.com/questions/9662346/python-code-to-remove-html-tags-from-a-string\n",
    "CLEANR = re.compile('<.*?>')\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleantext = re.sub(CLEANR, '', raw_html)\n",
    "    return cleantext\n",
    "\n",
    "cleaned_df = cleaned_df.apply(lambda x: x.astype(str).apply(lambda y: cleanhtml(y)))\n",
    "cleaned_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(tokenizer='spacy', language='en_core_web_sm')\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "cleaned_df['tokens'] = cleaned_df['review'].progress_apply(lambda x: tokenizer(x))\n",
    "# remove stop words\n",
    "# cleaned_df['tokens'] = cleaned_df['tokens'].progress_apply(lambda x: [word for word in x if word not in stopwords.words('english')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(cleaned_df.head()['tokens'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# build vocab\n",
    "cleaned_reviews = cleaned_df['tokens'].tolist()\n",
    "tokens = list(np.concatenate(cleaned_reviews).flat)\n",
    "\n",
    "counter = Counter(tokens)\n",
    "vocab = sorted(counter, key=counter.get, reverse=True)\n",
    "\n",
    "# convert words to integers\n",
    "vocab_to_int = {word: word_int for word_int, word in enumerate(vocab, 1)}\n",
    "vocab_to_int['<PAD>'] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert reviews to integers\n",
    "review_tokens = cleaned_df['tokens'].tolist()\n",
    "reviews_encoded = [[vocab_to_int[word] for word in review] for review in tqdm(review_tokens)]\n",
    "\n",
    "for i in range(5):\n",
    "    print(review_tokens[i][:5])\n",
    "    print(reviews_encoded[i][:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pad reviews\n",
    "\n",
    "def pad_features(reviews, pad_id, seq_length=200):\n",
    "    '''\n",
    "    Return features of review_ints, where each review is padded with 0's\n",
    "    or truncated to the input seq_length.\n",
    "    '''\n",
    "    features = np.full((len(reviews), seq_length), pad_id, dtype=int)\n",
    "\n",
    "    for i, row in enumerate(reviews):\n",
    "        features[i, :len(row)] = np.array(row)[:seq_length]\n",
    "\n",
    "    return features\n",
    "\n",
    "seq_length = 256\n",
    "features = pad_features(reviews_encoded, vocab_to_int['<PAD>'], seq_length=seq_length)\n",
    "\n",
    "assert len(features) == len(reviews_encoded), \"Your features should have as many rows as reviews.\"\n",
    "assert len(features[0]) == seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "print(features[:10, :10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get labels as numpy array\n",
    "labels = cleaned_df['sentiment'].tolist()\n",
    "labels = np.array([1 if label == 'positive' else 0 for label in labels])\n",
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create training, validation, and test data\n",
    "train_frac = 0.8  # 80% of data will be used for training\n",
    "validation_frac = 0.5  # 50% of test data will be used for validation (10% of total data)\n",
    "\n",
    "# create train set\n",
    "split_id = int(train_frac * len(features))\n",
    "train_x, remaining_x = features[:split_id], features[split_id:]\n",
    "train_y, remaining_y = labels[:split_id], labels[split_id:]\n",
    "\n",
    "# create validation and test set\n",
    "split_cal_id = int(validation_frac * len(remaining_x))\n",
    "val_x, test_x = remaining_x[:split_cal_id], remaining_x[split_cal_id:]\n",
    "val_y, test_y = remaining_y[:split_cal_id], remaining_y[split_cal_id:]\n",
    "\n",
    "print(\"Train set: \\t\\t\\t{}\".format(train_x.shape),\n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t\\t{}\".format(test_x.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(train_y[train_y==0]), len(train_y[train_y==1]))\n",
    "print(len(val_y[val_y==0]), len(val_y[val_y==1]))\n",
    "print(len(test_y[test_y==0]), len(test_y[test_y==1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "batch_size = 128\n",
    "\n",
    "# create tensor datasets\n",
    "train_set = torch.utils.data.TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "val_set = torch.utils.data.TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_set = torch.utils.data.TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check our batches are correct\n",
    "# expecting the shape to be (batch_size, seq_length) and the labels to be (batch_size)\n",
    "data_iter = iter(train_loader)\n",
    "x, y = data_iter.__next__()\n",
    "\n",
    "print('Sample input size: ', x.size())  # batch_size, seq_length\n",
    "print('Sample input: \\n', x)\n",
    "print()\n",
    "print('Sample label size: ', y.size())  # batch_size\n",
    "print('Sample label: \\n', y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "vocab_size = len(vocab_to_int)\n",
    "word_embeddings = np.array()\n",
    "for word in vocab_to_int.keys():\n",
    "    if word in glove_embeddings:\n",
    "        word_embeddings.append(np.array(glove_embeddings[word]))\n",
    "    else:\n",
    "        word_embeddings.append(np.zeros(25))\n",
    "print(len(word_embeddings), len(word_embeddings[0]))\n",
    "\n",
    "output_size = 1\n",
    "embedding_dim = 25\n",
    "hidden_dim = 256\n",
    "num_layers = 2\n",
    "dropout = 0.25\n",
    "\n",
    "model = SentimentRNN(word_embeddings=word_embeddings, output_dim=output_size, embedding_dim=embedding_dim, hidden_dim=hidden_dim, num_layers=num_layers, dropout=dropout)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training config\n",
    "lr = 0.001\n",
    "criterion = nn.BCELoss() # binary cross entropy loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "gradient_clip = 5\n",
    "epochs = 8\n",
    "print_every = 1\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'epochs': epochs\n",
    "}\n",
    "es_limit = 5  # early stopping limit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training loop\n",
    "\n",
    "epoch_loop = tqdm(range(epochs), position=0, desc='Training', leave=True)\n",
    "\n",
    "# early stopping trigger\n",
    "es_trigger = 0\n",
    "min_val_loss = torch.inf\n",
    "\n",
    "for epoch in epoch_loop:\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "\n",
    "    for idx, (feature, target) in enumerate(train_loader):\n",
    "        # add epoch meta info\n",
    "        epoch_loop.set_postfix_str(f'Training batch {idx}/{len(train_loader)}')\n",
    "\n",
    "        # move to device\n",
    "        feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "        # reset optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        feature = feature\n",
    "        out = model(feature)\n",
    "\n",
    "        # accuracy\n",
    "        pred = torch.tensor([1 if o > 0.5 else 0 for o in out], device=device)\n",
    "        equals = pred == target\n",
    "        acc = torch.mean(equals.type(torch.FloatTensor))\n",
    "        train_acc += acc.item()\n",
    "\n",
    "        # loss\n",
    "        loss = criterion(out.squeeze(), target.float())\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # clip gradient\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n",
    "\n",
    "        # update optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        # free some memory\n",
    "        del feature, target, pred\n",
    "\n",
    "    history['train_loss'].append(train_loss / len(train_loader))\n",
    "    history['train_acc'].append(train_acc / len(train_loader))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### References\n",
    "https://www.kaggle.com/code/affand20/imdb-with-pytorch"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
